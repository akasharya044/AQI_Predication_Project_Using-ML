{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvhmsdi45SBv+l5IEh3oqv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akasharya044/AQI_Predication_Project_Using-ML/blob/main/College_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Libaries Imports Here"
      ],
      "metadata": {
        "id": "evT446xqkkE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCXp9vTWlP2w",
        "outputId": "75d71a88-3891-4926-8613-921052a6c304"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.38.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_sample_data():\n",
        "    \"\"\"\n",
        "    Load sample AQI data for demonstration purposes\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pandas.DataFrame\n",
        "        A DataFrame containing sample AQI data\n",
        "    \"\"\"\n",
        "    # Create a sample dataset with realistic AQI data features\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Number of samples\n",
        "    n_samples = 1000\n",
        "\n",
        "    # Generate features related to air quality\n",
        "    pm25 = np.random.gamma(shape=2.0, scale=10.0, size=n_samples)  # PM2.5 levels\n",
        "    pm10 = pm25 * 1.5 + np.random.normal(0, 5, n_samples)  # PM10 levels\n",
        "    so2 = np.random.gamma(shape=1.0, scale=5.0, size=n_samples)  # SO2 levels\n",
        "    no2 = np.random.gamma(shape=1.5, scale=10.0, size=n_samples)  # NO2 levels\n",
        "    co = np.random.gamma(shape=0.5, scale=0.5, size=n_samples)  # CO levels\n",
        "    o3 = np.random.gamma(shape=1.0, scale=15.0, size=n_samples)  # O3 levels\n",
        "\n",
        "    # Temperature, humidity and wind features\n",
        "    temperature = np.random.normal(25, 10, n_samples)  # Temperature in °C\n",
        "    humidity = np.random.normal(60, 15, n_samples)  # Relative humidity (%)\n",
        "    wind_speed = np.random.gamma(shape=2.0, scale=2.0, size=n_samples)  # Wind speed in m/s\n",
        "\n",
        "    # Create temporal features\n",
        "    # Month (1-12)\n",
        "    month = np.random.randint(1, 13, n_samples)\n",
        "    # Season (1: Spring, 2: Summer, 3: Fall, 4: Winter)\n",
        "    season = np.ceil(month / 3) % 4 + 1\n",
        "\n",
        "    # Location type (urban, suburban, rural, industrial)\n",
        "    location_types = ['Urban', 'Suburban', 'Rural', 'Industrial']\n",
        "    location_type = np.random.choice(location_types, n_samples)\n",
        "\n",
        "    # Create AQI buckets based on the features\n",
        "    # Calculate a weighted sum as a proxy for AQI\n",
        "    aqi_proxy = (pm25 * 3.0 + pm10 * 1.5 + so2 * 2.0 + no2 * 2.0 +\n",
        "                co * 10.0 + o3 * 1.0 - wind_speed * 5.0 +\n",
        "                np.where(season == 2, 20, 0))  # Summer penalty\n",
        "\n",
        "    # Create AQI buckets\n",
        "    conditions = [\n",
        "        (aqi_proxy < 50),\n",
        "        (aqi_proxy >= 50) & (aqi_proxy < 100),\n",
        "        (aqi_proxy >= 100) & (aqi_proxy < 150),\n",
        "        (aqi_proxy >= 150) & (aqi_proxy < 200),\n",
        "        (aqi_proxy >= 200) & (aqi_proxy < 300),\n",
        "        (aqi_proxy >= 300)\n",
        "    ]\n",
        "\n",
        "    aqi_buckets = [\n",
        "        'Good',\n",
        "        'Moderate',\n",
        "        'Unhealthy for Sensitive Groups',\n",
        "        'Unhealthy',\n",
        "        'Very Unhealthy',\n",
        "        'Hazardous'\n",
        "    ]\n",
        "\n",
        "    aqi_bucket = np.select(conditions, aqi_buckets, default='Unknown')\n",
        "\n",
        "    # Create DataFrame\n",
        "    data = pd.DataFrame({\n",
        "        'PM2.5': pm25,\n",
        "        'PM10': pm10,\n",
        "        'SO2': so2,\n",
        "        'NO2': no2,\n",
        "        'CO': co,\n",
        "        'O3': o3,\n",
        "        'Temperature': temperature,\n",
        "        'Humidity': humidity,\n",
        "        'Wind_Speed': wind_speed,\n",
        "        'Month': month,\n",
        "        'Season': season,\n",
        "        'Location_Type': location_type,\n",
        "        'AQI_Bucket': aqi_bucket\n",
        "    })\n",
        "\n",
        "    # Add some missing values to make it more realistic\n",
        "    for col in data.columns:\n",
        "        if col != 'AQI_Bucket':  # Don't add missing values to the target column\n",
        "            # Add 2% missing values\n",
        "            mask = np.random.random(n_samples) < 0.02\n",
        "            data.loc[mask, col] = np.nan\n",
        "\n",
        "    return data\n",
        "\n",
        "def save_model(model, model_name):\n",
        "    \"\"\"\n",
        "    Save a trained model to disk\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : object\n",
        "        The trained model to save\n",
        "    model_name : str\n",
        "        The name to use for the saved model\n",
        "    \"\"\"\n",
        "    import joblib\n",
        "\n",
        "    # Create models directory if it doesn't exist\n",
        "    if not os.path.exists('models'):\n",
        "        os.makedirs('models')\n",
        "\n",
        "    # Save the model\n",
        "    joblib.dump(model, f'models/{model_name}.joblib')\n",
        "    print(f\"Model saved as models/{model_name}.joblib\")\n",
        "\n",
        "def load_model(model_name):\n",
        "    \"\"\"\n",
        "    Load a trained model from disk\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model_name : str\n",
        "        The name of the model to load\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    object\n",
        "        The loaded model\n",
        "    \"\"\"\n",
        "    import joblib\n",
        "\n",
        "    model_path = f'models/{model_name}.joblib'\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model file {model_path} not found\")\n",
        "\n",
        "    # Load the model\n",
        "    return joblib.load(model_path)"
      ],
      "metadata": {
        "id": "tsJ0zIlYl0a6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_correlation_heatmap(data):\n",
        "    \"\"\"\n",
        "    Plot a correlation heatmap for the given data\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : pandas.DataFrame\n",
        "        The data to plot the correlation heatmap for\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    matplotlib.figure.Figure\n",
        "        The figure object containing the heatmap\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    corr = data.corr()\n",
        "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 10))\n",
        "    sns.heatmap(\n",
        "        corr,\n",
        "        mask=mask,\n",
        "        cmap=cmap,\n",
        "        vmax=.3,\n",
        "        center=0,\n",
        "        square=True,\n",
        "        linewidths=.5,\n",
        "        cbar_kws={\"shrink\": .5},\n",
        "        annot=True,\n",
        "        fmt=\".2f\"\n",
        "    )\n",
        "    plt.title('Feature Correlation Heatmap')\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_feature_importance(model, feature_names, model_type='logistic'):\n",
        "    \"\"\"\n",
        "    Plot feature importance for the given model\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : object\n",
        "        The trained model (LogisticRegression or XGBClassifier)\n",
        "    feature_names : array-like\n",
        "        The names of the features\n",
        "    model_type : str\n",
        "        The type of model ('logistic' or 'xgboost')\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    matplotlib.figure.Figure\n",
        "        The figure object containing the feature importance plot\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    if model_type == 'logistic':\n",
        "        # For multi-class, take average of absolute coefficients across classes\n",
        "        if len(model.classes_) > 2:\n",
        "            importances = np.mean(np.abs(model.coef_), axis=0)\n",
        "        else:\n",
        "            importances = np.abs(model.coef_[0])\n",
        "    else:  # XGBoost\n",
        "        importances = model.feature_importances_\n",
        "\n",
        "    # Sort features by importance\n",
        "    indices = np.argsort(importances)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel('Feature Importance')\n",
        "\n",
        "    if model_type == 'logistic':\n",
        "        plt.title('Logistic Regression Coefficient Magnitudes')\n",
        "    else:\n",
        "        plt.title('XGBoost Feature Importance')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_confusion_matrix(cm, classes):\n",
        "    \"\"\"\n",
        "    Plot a confusion matrix\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    cm : array-like\n",
        "        The confusion matrix to plot\n",
        "    classes : array-like\n",
        "        The class labels\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    matplotlib.figure.Figure\n",
        "        The figure object containing the confusion matrix plot\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=classes,\n",
        "        yticklabels=classes\n",
        "    )\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_roc_curve(y_true, lr_probs, xgb_probs, classes):\n",
        "    \"\"\"\n",
        "    Plot ROC curves for both models\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_true : array-like\n",
        "        True target values\n",
        "    lr_probs : array-like\n",
        "        Predicted probabilities from Logistic Regression\n",
        "    xgb_probs : array-like\n",
        "        Predicted probabilities from XGBoost\n",
        "    classes : array-like\n",
        "        Class labels\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    matplotlib.figure.Figure\n",
        "        The figure object containing the ROC curve plot\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Convert y_true to one-hot encoding for multi-class ROC\n",
        "    y_true_dummies = pd.get_dummies(y_true, columns=classes).values\n",
        "\n",
        "    # Calculate ROC curve and AUC for each class for both models\n",
        "    for i, class_name in enumerate(classes):\n",
        "        # Logistic Regression\n",
        "        fpr_lr, tpr_lr, _ = roc_curve(y_true_dummies[:, i], lr_probs[:, i])\n",
        "        roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "        ax.plot(fpr_lr, tpr_lr, lw=2, alpha=0.7,\n",
        "                label=f'LR - {class_name} (AUC = {roc_auc_lr:.2f})')\n",
        "\n",
        "        # XGBoost\n",
        "        fpr_xgb, tpr_xgb, _ = roc_curve(y_true_dummies[:, i], xgb_probs[:, i])\n",
        "        roc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n",
        "        ax.plot(fpr_xgb, tpr_xgb, lw=2, alpha=0.7, linestyle='--',\n",
        "                label=f'XGB - {class_name} (AUC = {roc_auc_xgb:.2f})')\n",
        "\n",
        "    # Plot diagonal\n",
        "    ax.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "\n",
        "    ax.set_xlim([0.0, 1.0])\n",
        "    ax.set_ylim([0.0, 1.05])\n",
        "    ax.set_xlabel('False Positive Rate')\n",
        "    ax.set_ylabel('True Positive Rate')\n",
        "    ax.set_title('Receiver Operating Characteristic (ROC) Curves')\n",
        "    ax.legend(loc=\"lower right\")\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_prediction_comparison(y_true, lr_preds, xgb_preds):\n",
        "    \"\"\"\n",
        "    Plot a comparison of model predictions vs true values\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_true : array-like\n",
        "        True target values\n",
        "    lr_preds : array-like\n",
        "        Predictions from Logistic Regression\n",
        "    xgb_preds : array-like\n",
        "        Predictions from XGBoost\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    matplotlib.figure.Figure\n",
        "        The figure object containing the prediction comparison plot\n",
        "    \"\"\"\n",
        "    # Calculate accuracy per class\n",
        "    classes = np.unique(np.concatenate([y_true, lr_preds, xgb_preds]))\n",
        "\n",
        "    # Initialize dictionaries to store class accuracies\n",
        "    lr_class_acc = {}\n",
        "    xgb_class_acc = {}\n",
        "\n",
        "    for cls in classes:\n",
        "        # Get indices where true class is cls\n",
        "        idx = np.where(y_true == cls)[0]\n",
        "\n",
        "        if len(idx) > 0:\n",
        "            # Calculate class accuracy for Logistic Regression\n",
        "            lr_class_acc[cls] = np.sum(lr_preds[idx] == cls) / len(idx)\n",
        "\n",
        "            # Calculate class accuracy for XGBoost\n",
        "            xgb_class_acc[cls] = np.sum(xgb_preds[idx] == cls) / len(idx)\n",
        "\n",
        "    # Create a DataFrame for plotting\n",
        "    df = pd.DataFrame({\n",
        "        'Class': list(lr_class_acc.keys()),\n",
        "        'Logistic Regression': list(lr_class_acc.values()),\n",
        "        'XGBoost': list(xgb_class_acc.values())\n",
        "    })\n",
        "\n",
        "    # Melt the DataFrame for easier plotting\n",
        "    df_melted = pd.melt(df, id_vars=['Class'], var_name='Model', value_name='Accuracy')\n",
        "\n",
        "    # Create the plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    sns.barplot(x='Class', y='Accuracy', hue='Model', data=df_melted, ax=ax)\n",
        "\n",
        "    plt.title('Model Accuracy by Class')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title='Model')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n",
        "\n"
      ],
      "metadata": {
        "id": "us-PH9OImCQL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[server]\n",
        "headless = true\n",
        "address = \"0.0.0.0\"\n",
        "port = 5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "NMjDoQUmmYEN",
        "outputId": "e3b1ddfd-1c3c-4410-fa45-6d16e04e3e7b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'server' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-87470975154e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mheadless\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maddress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.0.0.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'server' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "ogTP-3NUjZ3o",
        "outputId": "a97adc12-b73d-43d2-ef27-eae13c09ea3c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (<ipython-input-13-61c6ad8756b0>, line 44)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-61c6ad8756b0>\"\u001b[0;36m, line \u001b[0;32m44\u001b[0m\n\u001b[0;31m    if 'X_train' not in st.session_state\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from preprocessing import preprocess_data, handle_missing_values, encode_categorical_features\n",
        "from models import train_logistic_regression, train_xgboost, evaluate_model\n",
        "from visualization import (\n",
        "    plot_correlation_heatmap,\n",
        "    plot_feature_importance,\n",
        "    plot_confusion_matrix,\n",
        "    plot_roc_curve,\n",
        "    plot_prediction_comparison\n",
        ")\n",
        "from utils import load_sample_data\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"AQI Prediction App\",\n",
        "    page_icon=\"🌍\",\n",
        "    layout=\"wide\",\n",
        "    initial_sidebar_state=\"expanded\"\n",
        ")\n",
        "\n",
        "# Define app title and description\n",
        "st.title(\"🌍 Air Quality Index (AQI) Prediction\")\n",
        "st.markdown(\"\"\"\n",
        "This application helps you predict Air Quality Index (AQI) using machine learning models.\n",
        "Upload your data, explore it, and compare the performance of Logistic Regression and XGBoost models.\n",
        "\"\"\")\n",
        "\n",
        "# Initialize session state variables if they don't exist\n",
        "if 'data' not in st.session_state:\n",
        "    st.session_state.data = None\n",
        "if 'preprocessed_data' not in st.session_state:\n",
        "    st.session_state.preprocessed_data = None\n",
        "if 'X_train' not in st.session_state\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lHWOaVIGlW-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}